\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
% \usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{apacite} % APA style citations
\AtBeginDocument{\urlstyle{APACsame}}  % Links in APA citations same formatting
\usepackage{tabulary}
\usepackage{natbib} % natbib citations: \citep{} and \citet{} for in-text
\usepackage{booktabs}
% If you use \tableofcontents, this adjusts the name
%\addto\captionsenglish{\renewcommand*\contentsname{Table of Contents}}
\setcounter{MaxMatrixCols}{20} % https://tex.stackexchange.com/questions/436646/matrix-extra-alignment-tab-has-been-changed-to-cr


\title{\textbf{Dynamic Factor Models}\\ A Very Short Introduction}
\author{Sebastian Krantz}

\begin{document}
\maketitle

Dynamic factor models (DFMs) postulate that a small number of latent factors explain the common dynamics of a larger number of observed time series \citep{stock2016dynamic}. DFMs provide estimates of these unobserved factors and their joint dynamics, with many applications in forecasting, time series interpolation, and macroeconomic monitoring, such as the creation of coincident business cycle indicators \citep{mariano2003new}. Another popular application is "nowcasting", where large volumes of time series data released at higher frequencies are synthesized to produce real-time estimates of low-frequency leading indicators such as GDP \citep{bok2018macroeconomic}. \newline

DFMs are set up in State Space form and can be estimated using the Kalman Filter and several solution algorithms. The most popular one in the economics literature is the Expectation Maximization (EM) algorithm, due to its robust numerical properties \citep{doz2012quasi} and the popular mixed frequency generalization of \citet{banbura2014maximum}. % \newline

\section{The Canonical (Exact) DFM}

A canonical baseline dynamic factor model can be written as
\begin{align} \label{eq:do}
\textbf{x}_t &= \textbf{C}_0 \textbf{f}_t + \textbf{e}_t, \qquad\qquad\, \textbf{e}_t\sim N(\textbf{0}, \textbf{R}) \\ \label{eq:dt}
\textbf{f}_t &= \sum_{j=1}^p \textbf{A}_j \textbf{f}_{t-j} + \textbf{u}_t, \quad\ \textbf{u}_t\sim  N(\textbf{0}, \textbf{Q}_0),
\end{align}
\noindent where Eq. \ref{eq:do} is called the measurement or observation equation and Eq. \ref{eq:dt} is called transition, state, or process equation, allowing the unobserved factors $\textbf{f}_t$ to evolve according to a VAR(p) process. These equations do not include trend or intercept terms, as the data $\textbf{x}_t$ is made stationary and standardized (scaled and centered) before estimation. The system's matrices are \newline

\begin{tabular}{p{1cm}p{12cm}}
$\textbf{x}_t$ & $n \times 1$ vector of observed series at time $t$: $(x_{1t}, \dots, x_{nt})'$ (allows missing data)  \\[1em]
$\textbf{f}_t$ & $r \times 1$ vector of factors at time $t$: $(f_{1t}, \dots, f_{rt})'$\\[1em]
$\textbf{C}_0$ & $n \times r$ measurement (observation) matrix\\[1em]
$\textbf{A}_j$ & $r \times r$ state transition matrix at lag $j$ \\[1em]
$\textbf{Q}_0$ & $r \times r$ state covariance matrix\\[1em]
$\textbf{R}$ & $n \times n$ measurement (observation) covariance matrix. It is diagonal by the assumption that all covariation between the series is explained by the factors: $E[x_{it}|\textbf{x}_{-i,t},\textbf{f}_t] = \textbf{c}_{0i}\textbf{f}_t\ \forall i$, with $\textbf{c}_{0i}$ the i-th row of $\textbf{C}_0$.
\end{tabular}
\\\\

This model can be estimated using a classical form of the Kalman Filter and the Expectation Maximization (EM) algorithm, after transforming it to State Space (stacked, VAR(1)) form
\begin{align}
\textbf{x}_t &= \textbf{C} \textbf{F}_t + \textbf{e}_t, \qquad\ \ \textbf{e}_t\sim N(\textbf{0}, \textbf{R}) \\
\textbf{F}_t &= \textbf{AF}_{t-1} + \textbf{u}_t, \quad\ \textbf{u}_t\sim  N(\textbf{0}, \textbf{Q}),
\end{align}
where $\textbf{x}_t$, $\textbf{e}_t$ and \textbf{R} are as in Eq. \ref{eq:do}, and the other matrices are

\newpage

\begin{align} \vspace{-4cm}
\textbf{F}_{t\ (rp \times 1)}  &= (\textbf{f}_t', \textbf{f}_{t-1}', \dots, \textbf{f}_{t-p}')' = (f_{1t}, \dots, f_{rt}, f_{1,t-1}, \dots, f_{r,t-1}, \dots, f_{1,t-p}, \dots, f_{r,t-p})' \\[1em]
\textbf{C}_{(n \times rp)}  &= (\textbf{C}_0, \textbf{0}, \dots, \textbf{0}), \text{where \textbf{0} are $n\times r$ matrices of zeros for each factor lag} \\[1em]
\textbf{A}_{(rp \times rp)}  &= \begin{pmatrix}
\textbf{A}_1 & \textbf{A}_2 & \cdots & \textbf{A}_{p-1}  & \textbf{A}_p \\
\textbf{I}_1 & \textbf{0} & \cdots & \textbf{0} & \textbf{0} \\
\textbf{0} & \textbf{I}_2 & \cdots & \textbf{0} & \textbf{0} \\ 
\vdots & \vdots & \ddots & \vdots & \vdots \\
\textbf{0} & \textbf{0} & \cdots & \textbf{I}_{p-1} & \textbf{0}
\end{pmatrix}, \text{where \textbf{0}/\textbf{I} are $r\times r$ zero/identity matrices} \\[1em]
\textbf{u}_{t\ (rp \times 1)}  &= (\textbf{u}_t', \textbf{0}', \dots, \textbf{0}')', \text{with \textbf{0} a $r \times 1$ vector of zeros}  \\[1em]
\textbf{Q}_{(rp \times rp)}  &= \begin{pmatrix}
\textbf{Q}_0 & \textbf{0} & \cdots & \textbf{0} \\
\textbf{0} & \textbf{0}& \cdots & \textbf{0} \\ 
\vdots & \vdots & \ddots & \vdots  \\
\textbf{0} & \textbf{0} & \cdots & \textbf{0}
\end{pmatrix}, \text{where \textbf{0} are $r\times r$ zero matrices.} 
\end{align}

The estimation of this model via quasi-maximum likelihood using the EM algorithm, with initial system matrices determined through Principal Components Analysis (suitable for large $n$), is described in \citet{doz2012quasi}. \newline

This \emph{exact} DFM specification is quite restrictive as it assumes that all correlation in the data is explained by the unobserved common factors. In particular, it assumes

\begin{enumerate}
\item Linearity and constant relationships (no structural breaks)
\item Idiosynchratic measurement (observation) errors (\textbf{R} is diagonal)
\item No direct relationship between series and lagged factors (can be relaxed)
\item No relationship between lagged error terms in either measurement or transition equation (no serial correlation).
\end{enumerate}

Particularly assumption 4 is quite restrictive since it stipulates that all time dynamics in $\textbf{x}_t$ need to be accounted for by the factors. \newline

Within the framework of the \emph{exact} DFM, assumption 3 can easily be relaxed to allow $q$ lags of the factors in the measurement equation
\begin{equation}
\textbf{x}_t = \sum_{i=0}^q \textbf{C}_i \textbf{f}_{t-i} + \textbf{e}_t, \qquad \textbf{e}_t\sim N(\textbf{0}, \textbf{R}).
\end{equation}
In this case, the stacked notation remains the same as long as $q < r-1$, with observation matrix 
\begin{equation} \label{eq:Clags}
\textbf{C}_{(n \times rp)}  = (\textbf{C}_0, \textbf{C}_1, \dots, \textbf{C}_q, \textbf{0}, \dots, \textbf{0})
\end{equation}
modified to estimate the lagged loadings $\textbf{C}_i$. However, because of the proliferation of parameters, this extension has not received much attention in frequentist estimation approaches. Furthermore, in the presence of significant lagged dynamics, increasing the number of factors $r$ is often successful in capturing these dynamics, with certain factors loading strongly on the lagged indicators and others on the contemporaneous ones. \newline


In the current practice of estimating large DFMs of economic time series, series for a given sector often have unmodeled sector-specific dynamics. Most of the economics literature on DFMs has thus focused on relaxing restrictions about the error structure in factor models, introducing the notion of \emph{approximate} factor models \citep{stock2016dynamic}. A particular emphasis has been placed on relaxing assumption 4, i.e. allowing some of the idiosyncratic dynamics of the time series to be unexplained by the common factors. 
% doz2020dynamic


\section{Approximate DFMs}

The most common form of \emph{approximate} DFM, introduced by \citet{chamberlain2983arbitrage}, allows for the observation errors $\textbf{e}_t$ to evolve according to an autoregressive AR(1) process
\begin{equation} \label{eq:ar1}
\textbf{e}_t = \mathbf{\Phi} \textbf{e}_{t-1} + \textbf{v}_t,\quad \textbf{v}_t\sim N(\textbf{0}, \textbf{R}),
\end{equation}
where $\mathbf{\Phi}$ is diagonal $n\times n$ with autoregressive parameters $\rho_i$ along the diagonal and zeros otherwise. Following \citet{banbura2014maximum}, the autoregressive dynamics can be modeled as part of the state vector. 
%rewriting the dynamic form given by Equations \ref{eq:do} and \ref{eq:dt} as
% \textbf{x}_t = \textbf{C}_0^a \textbf{f}_t^a + \textbf{v}_t \quad \text{with} \quad \textbf{f}_t^a = (\textbf{f}_t', \textbf{e}_{t-1}')', \quad \textbf{C}_0^a = (\textbf{C}_0, \mathbf{\Phi}),\quad \textbf{v}_t\sim N(\textbf{0}, \textbf{R}),
%\begin{align}
%\textbf{x}_t &= \textbf{C}_0^a \textbf{f}_t^a \qquad\qquad\quad\ \ \text{with} \quad \textbf{f}_t^a = (\textbf{f}_t', \textbf{e}_t')', \quad \textbf{C}_0^a = (\textbf{C}_0, \textbf{I}) \\
%\textbf{f}_t^a &= \sum_{j=1}^p \textbf{A}_j^a \textbf{f}_{t-j}^a + \textbf{u}_t \quad \text{with} \quad \textbf{A}_1^a = (\textbf{A}_1, \mathbf{\Phi}),\quad \textbf{A}_{j>1}^a = (\textbf{A}_{j>1}, \textbf{0}), \quad \textbf{u}_t\sim  N(\textbf{0}, \textbf{Q}_0).
%\end{align}
In the stacked form, the model becomes 
\begin{align} \label{eq:doar1}
\textbf{x}_t &= \textbf{C}^a \textbf{F}_t^a \\
\textbf{F}_t^a &= \textbf{A}^a\textbf{F}^a_{t-1} + \textbf{u}_t^a, \quad\ \textbf{u}_t^a\sim  N(\textbf{0}, \textbf{Q}^a),
\end{align}
where $\textbf{x}_t$ is as in Eq. \ref{eq:do}, and the other matrices are

\begin{align}
\textbf{F}^a_{t\ (rp+n \times 1)}  &= (\textbf{f}_t', \textbf{f}_{t-1}', \dots, \textbf{f}_{t-p}', \textbf{e}_t')', \text{where $\textbf{e}_t$ is $n\times 1$ as in Eq. \ref{eq:ar1}} \\[1em]
\textbf{C}^a_{(n \times rp+n)}  &= (\textbf{C}_0, \textbf{0}, \dots, \textbf{0}, \textbf{I}), \text{where \textbf{0} is $n\times r$ and \textbf{I} is $n\times n$} \\[1em]
\textbf{A}^a_{(rp+n \times rp+n)}  &= \begin{pmatrix}
\textbf{A} & \textbf{0} \\
\textbf{0} & \mathbf{\Phi}
\end{pmatrix} = \begin{pmatrix}
\textbf{A}_1 & \textbf{A}_2 & \cdots & \textbf{A}_{p-1}  & \textbf{A}_p & \textbf{0}\\
\textbf{I}_1 & \textbf{0} & \cdots & \textbf{0} & \textbf{0} & \textbf{0} \\
\textbf{0} & \textbf{I}_2 & \cdots & \textbf{0} & \textbf{0} & \textbf{0} \\ 
\vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
\textbf{0} & \textbf{0} & \cdots & \textbf{I}_{p-1} & \textbf{0} & \textbf{0} \\
\textbf{0} & \textbf{0} & \cdots & \textbf{0} & \textbf{0} & \mathbf{\Phi}
\end{pmatrix}, \text{where $\mathbf{\Phi}$ is $n\times n$ as in Eq. \ref{eq:ar1}} \\[1em]
\textbf{u}^a_{t\ (rp+n \times 1)}  &= (\textbf{u}_t', \textbf{0}', \dots, \textbf{0}', \textbf{v}_t')', \text{with $\textbf{v}_t$ $n \times 1$ as in Eq. \ref{eq:ar1}}  \\[1em]
\textbf{Q}^a_{(rp+n \times rp+n)}  &= \begin{pmatrix}
\textbf{Q} & \textbf{0} \\
\textbf{0} & \textbf{R}
\end{pmatrix} = \begin{pmatrix}
\textbf{Q}_0 & \textbf{0} & \cdots &  \textbf{0} \\
\textbf{0} & \textbf{0}& \cdots  & \textbf{0} \\ 
\vdots & \vdots & \ddots  & \vdots \\
\textbf{0} & \textbf{0} & \cdots & \textbf{R}
\end{pmatrix}, \text{where \textbf{R} is $n\times n$ as in Eq. \ref{eq:ar1}.} 
\end{align}

To still be able to estimate this model using a classical form of the Kalman Filter, \citet{banbura2014maximum} introduce an error term $\textbf{z}_t \sim N(\textbf{0}, \kappa \textbf{I})$ in Eq. \ref{eq:doar1}, with $\kappa$ a very small number. \newline

Like the \emph{exact} DFM, this model can also easily be extended to allow for $q$ factor lags in the observation equation, by estimating an observation matrix
\begin{equation}
\textbf{C}^a_{(n \times rp+n)}  = (\textbf{C}_0, \textbf{C}_1, \dots, \textbf{C}_q, \textbf{0}, \dots, \textbf{0}, \textbf{I}).
\end{equation}

The same comments given above about the proliferation of parameters and the possibility to include additional factors to account for lagged dynamics apply. \newline 

In general, \citet{doz2011two, doz2012quasi} show that in the presence of serial correlation, the factors are still consistently estimated as $n, T \to \infty$ using an \emph{exact} DFM specification. Thus modeling serial correlation is particularly important in smaller samples. \citet{banbura2014maximum} also show that modeling the serial correlation improves forecast accuracy, but only at short horizons.

\newpage 

\section{Mixed Frequency}

Building on the work of \citet{mariano2003new}, \citet{banbura2014maximum} and \citet{bok2018macroeconomic} (New York FED Nowcast) popularized EM-based estimation of large mixed-frequency (monthly and quarterly) DFMs as workhorse models in economic nowcasting practice. The key addition of \citet{mariano2003new} was to model observed quarterly series by unobserved monthly counterparts and then place appropriate restrictions on the observation matrix (\textbf{C}). \newline 

In particular, \citet{mariano2003new} consider the case of an observed quarterly series $X^q_t$ being the geometric mean of an unobserved monthly series $\tilde{X}^m_t$ and it's lags, i.e.
\begin{equation}
X^q_t = \tilde{X}^{m\frac{1}{3}}_t\tilde{X}^{m\frac{1}{3}}_{t-1}\tilde{X}^{m\frac{1}{3}}_{t-2},
\end{equation}
such that taking the natural log yields
\begin{equation}
\log(X^q_t) = \frac{1}{3}\log(\tilde{X}^m_t) + \frac{1}{3}\log(\tilde{X}^m_{t-1}) + \frac{1}{3}\log(\tilde{X}^m_{t-2}).
\end{equation}
Lagging this equation 3 times and subtracting it from itself yields the (approximate) quarterly growth rate of the quarterly series
\begin{equation}
\log(X^q_t) - \log(X^q_{t-3}) = \frac{1}{3}[\log(\tilde{X}^m_t) - \log(\tilde{X}^m_{t-3})] + \frac{1}{3}[\log(\tilde{X}^m_{t-1})-\log(\tilde{X}^m_{t-4})] + \frac{1}{3}[\log(\tilde{X}^m_{t-2})-\log(\tilde{X}^m_{t-5})].
\end{equation}
Adding and subtracting further lags on the right-hand side, and denoting the growth rate by lowercase letters, i.e. $x^q_t = \log(X^q_t) - \log(X^q_{t-3})$ and $\tilde{x}^m_t = \log(\tilde{X}^m_t) - \log(\tilde{X}^m_{t-1})$, yields
\begin{align}
x^q_t &= \frac{1}{3}[\tilde{x}^m_t + \tilde{x}^m_{t-1} + \tilde{x}^m_{t-2}] + \frac{1}{3}[\tilde{x}^m_{t-1} + \tilde{x}^m_{t-2} + \tilde{x}^m_{t-3}] + \frac{1}{3}[\tilde{x}^m_{t-2} + \tilde{x}^m_{t-3} + \tilde{x}^m_{t-4}] \\
 &= \frac{1}{3}\tilde{x}^m_t + \frac{2}{3}\tilde{x}^m_{t-1} + \tilde{x}^m_{t-2} + \frac{2}{3}\tilde{x}^m_{t-3} + \frac{1}{3}\tilde{x}^m_{t-4}.
\end{align}
This is the result of \citet{mariano2003new}. \citet{banbura2014maximum} consider instead the quarterly series to be the product of the unobserved monthly series, i.e. starting from $X^q_t = \tilde{X}^m_t\tilde{X}^m_{t-1}\tilde{X}^m_{t-2}$, the final expression is
\begin{equation} \label{eq:MMBM}
x^q_t = \tilde{x}^m_t + 2\tilde{x}^m_{t-1} + 3\tilde{x}^m_{t-2} + 2\tilde{x}^m_{t-3} + \tilde{x}^m_{t-4}.
\end{equation}
Since $\tilde{X}^m_t$ (and thus $\tilde{x}^m_t$) is unobserved, this approach is equivalent, as only the relative weights on the lags of the unobserved series matter. We now assume that there exist $n_Q$ quarterly variables, whose vector of unobserved monthly counterparts $\tilde{\textbf{x}}^m_t$ admits the same DFM representation as the observed monthly variables, i.e. $\tilde{\textbf{x}}^m_t = \textbf{C}_0^q\textbf{f}_t + \textbf{e}^q_t$. Inserting in a vectorized version of Eq. \ref{eq:MMBM} yields
\begin{align} 
\textbf{x}^q_t &= \textbf{C}_0^q\textbf{f}_t + \textbf{e}^q_t + 2(\textbf{C}_0^q\textbf{f}_{t-1} + \textbf{e}^q_{t-1}) + 3(\textbf{C}_0^q\textbf{f}_{t-2} + \textbf{e}^q_{t-2}) + 2(\textbf{C}_0^q\textbf{f}_{t-3} + \textbf{e}^q_{t-3}) + \textbf{C}_0^q\textbf{f}_{t-4} + \textbf{e}^q_{t-4} \\
&= \textbf{C}_0^q (\textbf{I}\ 2\textbf{I}\ 3\textbf{I}\ 2\textbf{I}\ \textbf{I})(\textbf{f}_t'\ \textbf{f}_{t-1}'\ \textbf{f}_{t-2}'\ \textbf{f}_{t-3}'\ \textbf{f}_{t-4}')' + (\textbf{I}\ 2\textbf{I}\ 3\textbf{I}\ 2\textbf{I}\ \textbf{I})(\textbf{e}^{q\prime}_t\ \textbf{e}^{q\prime}_{t-1}\ \textbf{e}^{q\prime}_{t-2}\ \textbf{e}^{q\prime}_{t-3}\ \textbf{e}^{q\prime}_{t-4})' \\
&= \textbf{C}_0^q\textbf{J}\textbf{F}^5_t + \textbf{J}\textbf{E}^5_t \\
&= \textbf{C}^q\textbf{F}^q_t,
\end{align}
where the latter is a stacked representation similar to the \emph{approximate} DFM case, with matrices
\begin{align} \label{eq:Ftmf}
\textbf{F}^q_{t\ (5r+5n_Q \times 1)}  &= (\textbf{F}^{5\prime}_t, \textbf{E}_t^{5\prime})' = (\textbf{f}_t', \dots, \textbf{f}_{t-4}', \textbf{e}^{q\prime}_t, \dots, \textbf{e}^{q\prime}_{t-4})', \text{where $\textbf{f}_t$ is $r\times 1$ and $\textbf{e}^q_t$ is $n_Q\times 1$} \\[1em]
\textbf{C}^q_{(n \times 5r+5n_Q)}  &= (\textbf{C}_0^q\textbf{J}, \textbf{J}) = (\textbf{C}_0^q, 2\textbf{C}_0^q, 3\textbf{C}_0^q, 2\textbf{C}_0^q, \textbf{C}_0^q, \textbf{I}, 2\textbf{I}, 3\textbf{I}, 2\textbf{I}, \textbf{I}), \text{where \textbf{I} is $n_Q\times n_Q$.}
\end{align}
In other words, mixed frequency estimation amounts to modeling the error process of unobserved variables as part of the state vector and placing restrictions on the observation matrix. Provided that the number of lags in the transition equation is $p > 4$, and assuming that quarterly series $\textbf{x}_t^q$ are observed every 3rd month and missing otherwise, the joint monthly-quarterly state space representation can be modeled as 
\begin{align} \label{eq:domf}
\tilde{\textbf{x}}_t &= \tilde{\textbf{C}} \tilde{\textbf{F}}_t + \tilde{\textbf{e}}_t, \ \qquad\ \tilde{\textbf{e}}_t\sim  N(\textbf{0}, \tilde{\textbf{R}}) \\
\tilde{\textbf{F}}_t &= \tilde{\textbf{A}}\tilde{\textbf{F}}_{t-1} + \tilde{\textbf{u}}_t, \quad\ \tilde{\textbf{u}}_t\sim  N(\textbf{0}, \tilde{\textbf{Q}}),
\end{align}
with system matrices
\begin{align}
\tilde{\textbf{x}}_{t\ (n \times 1)} &= (\textbf{x}_t^{m\prime},\ \textbf{x}_t^{q\prime})', \text{where $\textbf{x}_t^m$ is $n_M\times 1$ and $\textbf{x}_t^q$ is $n_Q\times 1$} \\[1em]
\tilde{\textbf{F}}_{t\ (rp+5n_Q \times 1)}  &= (\textbf{f}_t', \dots, \textbf{f}_{t-p}', \textbf{e}^{q\prime}_t, \dots, \textbf{e}^{q\prime}_{t-4})', \text{where $\textbf{e}^q_t$ is $n_Q\times 1$ as in Eq. \ref{eq:Ftmf}} \\[1em] \label{eq:Cmf}
\tilde{\textbf{C}}_{(n \times rp+5n_Q)}  &= \begin{pmatrix}
\textbf{C}^m & \textbf{0} & \textbf{0} \\
\textbf{C}_0^q\textbf{J} & \textbf{0} & \textbf{J}
\end{pmatrix} = \begin{pmatrix}
\textbf{C}_0^m & \textbf{0} & \textbf{0} & \textbf{0} & \textbf{0} & \textbf{0} & \textbf{0} & \textbf{0} & \textbf{0} & \textbf{0} & \textbf{0} \\
\textbf{C}_0^q & 2\textbf{C}_0^q & 3\textbf{C}_0^q & 2\textbf{C}_0^q & \textbf{C}_0^q & \textbf{0} & \textbf{I} & 2\textbf{I} & 3\textbf{I} & 2\textbf{I} & \textbf{I}
\end{pmatrix} \\
\tilde{\textbf{e}}_{t\ (n \times 1)}  &= (\textbf{e}^{m\prime}_t, \textbf{z}^{q\prime}_t)', \text{where $\textbf{e}^m_t$ is $n_M \times 1$, and $\textbf{z}^q_t$ is $n_Q \times 1$ and very small}  \\[1em]
\tilde{\textbf{R}}_{(n \times n)}  &= \begin{pmatrix}
\textbf{R}^m & \textbf{0} \\
\textbf{0} & \kappa\textbf{I}
\end{pmatrix}, \text{where $\textbf{R}^m$ is $n_M\times n_M$, \textbf{I} is $n_Q\times n_Q$, and $\kappa$ very small} \\[1em]
\tilde{\textbf{A}}_{(rp+5n_Q \times rp+5n_Q)}  &= \begin{pmatrix}
\textbf{A} & \textbf{0} \\
\textbf{0} & \textbf{I}^q
\end{pmatrix} = \begin{pmatrix}
\textbf{A}_1 & \textbf{A}_2 & \cdots & \textbf{A}_{p-1}  & \textbf{A}_p & \textbf{0}\\
\textbf{I}_1 & \textbf{0} & \cdots & \textbf{0} & \textbf{0} & \textbf{0} \\
\textbf{0} & \textbf{I}_2 & \cdots & \textbf{0} & \textbf{0} & \textbf{0} \\ 
\vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
\textbf{0} & \textbf{0} & \cdots & \textbf{I}_{p-1} & \textbf{0} & \textbf{0} \\
\textbf{0} & \textbf{0} & \cdots & \textbf{0} & \textbf{0} & \textbf{I}^q
\end{pmatrix}, \text{where $\textbf{I}^q$ is $5n_Q\times 5n_Q$} \\
\tilde{\textbf{u}}_{t\ (rp+5n_Q \times 1)}  &= (\textbf{u}_t', \textbf{0}', \dots, \textbf{0}', \textbf{e}^{q\prime}_t, \textbf{0}', \dots, \textbf{0}')', \text{where $\textbf{e}^q_t$ is $n_Q \times 1$} \\[1em]
\tilde{\textbf{Q}}_{(rp+5n_Q \times rp+5n_Q)}  &= \begin{pmatrix}
\textbf{Q}_0 & \textbf{0} & \textbf{0} & \textbf{0} \\
\textbf{0} & \textbf{0} & \textbf{0} & \textbf{0} \\
\textbf{0} & \textbf{0} & \textbf{R}^q & \textbf{0} \\ 
\textbf{0} & \textbf{0} & \textbf{0} & \textbf{0}
\end{pmatrix}, \text{where $\textbf{R}^q$ is $n_Q\times n_Q$.} 
\end{align}

This representation can easily be extended to allow additional lags of monthly variables in the observation equation, by replacing $\textbf{C}^m$ in Eq. \ref{eq:Cmf} by a suitably altered version as in Eq. \ref{eq:Clags}. It is also possible to estimate autoregressive parameters, by also including $\textbf{e}^m_t$ into the state vector $\tilde{\textbf{F}}$, replacing $\tilde{\textbf{e}}_t$ by a very small amplitude process $\tilde{\textbf{z}}_t$ with covariance $\kappa\textbf{I}$, adding autoregressive parameters $\mathbf{\Phi}^m$ and $\mathbf{\Phi}^q$ to $\tilde{\textbf{A}}$, and estimating both $\textbf{R}^m$ and $\textbf{R}^q$ inside $\tilde{\textbf{Q}}$. The modified EM algorithm that respects the restrictions placed on $\tilde{\textbf{C}}$ is detailed in \citet{banbura2014maximum}.


% \newpage

\bibliographystyle{apacite}
\bibliography{dynamic_factor_models} % This links to a file bibliography.bib with the citations

\end{document}
